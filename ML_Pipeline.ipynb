{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c376e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as tp\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80be375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.sql.shuffle.partitions\", \"200\").config(\"spark.executor.memory\", \"4g\").config(\"master\", \"yarn\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e95686f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g01.itversity.com:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd165c4e780>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3726e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv(\"dataset/ml_project/train.csv\",header = True, inferSchema = True)\n",
    "test = spark.read.csv(\"dataset/ml_project/test.csv\",header = True, inferSchema = True)\n",
    "valid = spark.read.csv(\"dataset/ml_project/valid.csv\",header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380043c",
   "metadata": {},
   "source": [
    "## Varibale Identification - numeric/categorical/temporal/boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c91d778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Carrier: double (nullable = true)\n",
      " |-- TrafficType: string (nullable = true)\n",
      " |-- ClickDate: string (nullable = true)\n",
      " |-- Device: string (nullable = true)\n",
      " |-- Browser: string (nullable = true)\n",
      " |-- OS: string (nullable = true)\n",
      " |-- ConversionStatus: boolean (nullable = true)\n",
      " |-- publisherId: string (nullable = true)\n",
      " |-- advertiserCampaignId: double (nullable = true)\n",
      " |-- Fraud: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9148434",
   "metadata": {},
   "source": [
    "### Type casting target variable in test, train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94894b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn(\"ConversionStatus\",F.col(\"ConversionStatus\").cast(tp.IntegerType()))\n",
    "test = test.withColumn(\"ConversionStatus\",F.col(\"ConversionStatus\").cast(tp.IntegerType()))\n",
    "valid = valid.withColumn(\"ConversionStatus\",F.col(\"ConversionStatus\").cast(tp.IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd97c8f",
   "metadata": {},
   "source": [
    "PIPELINE STEPS:\n",
    "stage1 : Transformer - fill na values in each column \n",
    "\n",
    "stage2: Transform - Reduce categories by udf functions \n",
    "\n",
    "stage3: Estimator - Label ENcode TrafficType \n",
    "\n",
    "stage4: Estimator - Label ENcode OS \n",
    "\n",
    "stage5: Estimator - Label ENcode Country \n",
    "\n",
    "stage6: Estimator - Label ENcode Browser \n",
    "\n",
    "stage7: Estimator - OneHotEncode OS, Browser, Country, Device \n",
    "\n",
    "stage8: Transform - Create columns total clicks/publisher-id and total clicks pers adveriser-id \n",
    "\n",
    "stage9: Transform - CReate Vector with OS_ohe, Browser_ohe, Country_ohe, TrafficType, Device_ohe, Fraud,total \n",
    "clicks/publisher-id and total clicks pers adveriser-id as feature_vector \n",
    "\n",
    "stage10: Estimator - Predict labels using LogisticRegession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743a9e0",
   "metadata": {},
   "source": [
    "### Count the number of missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15783126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "class fillNaValues(Transformer):\n",
    "    def __init__(self, x = None):\n",
    "        self.dataset = x\n",
    "    def _transform(self,dataset):\n",
    "        dataset = dataset.fillna({\"Country\":\"IN\",\n",
    "                                           \"TrafficType\":\"U\",\n",
    "                                           \"Device\":\"Generic\",\n",
    "                                           \"OS\":\"Android\",\n",
    "                                           \"Fraud\":0,\n",
    "                                           \"Browser\":\"chrome\"})\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81d9fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countries_mapping(x):\n",
    "    top_20_countries = ['IN','TH','ID','BD','MX','BR','RU','NG','MY','US','BO','PH','ZA','VE','GT','DZ','KR','CO','IQ','AE']\n",
    "    if x in top_20_countries:\n",
    "        return x\n",
    "    else:\n",
    "        return \"others\"\n",
    "udf_country = F.udf(f = countries_mapping, returnType = tp.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f70a0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_mapping(x):\n",
    "    if x in [\"Generic\"]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "udf_device = F.udf(f = device_mapping, returnType = tp.IntegerType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a1cbb",
   "metadata": {},
   "source": [
    "# Browser \n",
    "* chrome : convert android_webkit, chrome, 46.0.2490.76(chrome version) and chromium\n",
    "* Safari : phone, safari\n",
    "* firefox : firefox_mobile, firefox, firefox_desktop\n",
    "* others : rest of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5627db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def browser_mapping(x):\n",
    "    if x in [\"android_webkit\",\"chrome\",\"46.0.2490.76\",\"Chromium\"]:\n",
    "        return \"chrome\"\n",
    "    elif x in [\"iphone\",\"safari\"]:\n",
    "        return \"safari\"\n",
    "    elif x in [\"firefox_mobile\",\"firefox\",\"firefoc_desktop\"]:\n",
    "        return \"firefox\"\n",
    "    else:\n",
    "        return \"others\"\n",
    "udf_browser = F.udf(f = browser_mapping, returnType = tp.StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d0a403",
   "metadata": {},
   "source": [
    "## OS - 15 categories\n",
    "* Android: Android\n",
    "* ios : Mac OS X , IOS\n",
    "* others : rest of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "349c3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def os_mapping(x):\n",
    "    if x in [\"Android\"]:\n",
    "            return \"Android\"\n",
    "    elif x in [\"Mac OS X\", \"IOS\"]:\n",
    "        return \"ios\"\n",
    "    else:\n",
    "        return \"Others\"\n",
    "udf_os = F.udf(f = os_mapping, returnType = tp.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4345ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reduceCategories(Transformer):\n",
    "    def __init__(self,dataframe = None):\n",
    "        self.dataframe = dataframe\n",
    "    def _transform(self, dataset):\n",
    "        dataset = dataset.withColumn(\"Country\",udf_country(dataset[\"Country\"]))\n",
    "        dataset = dataset.withColumn(\"OS\", udf_os(dataset[\"OS\"]))\n",
    "        dataset = dataset.withColumn(\"Browser\", udf_browser(dataset[\"Browser\"]))\n",
    "        \n",
    "        #Device mapping is 0's and 1's so no need to LE and OHE\n",
    "        dataset = dataset.withColumn(\"Device\", udf_device(dataset[\"Device\"]))\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292df6a7",
   "metadata": {},
   "source": [
    "## PublisherId 2000 distict categories so --> PublisherId/frequency\n",
    "### groupby publisherId and count on ConversionStatus as total_p_id\n",
    "### Join this dataframe with original train df\n",
    "*** this is a numeric column which as fixed number of distict values resulting in this transfomations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f736b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_p_id = train.groupBy(\"PublisherId\").agg(F.count(\"ConversionStatus\").alias(\"pub-id\"))\n",
    "total_c_id = train.groupBy(\"advertiserCampaignId\").agg(F.count(\"ConversionStatus\").alias(\"camp-id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b53ea05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class frequencyEncoding(Transformer):\n",
    "    def __init__(self,dataframe = None):\n",
    "        self.dataframe = dataframe\n",
    "    def _transform(self,dataset):\n",
    "        \n",
    "        dataset = dataset.join(total_c_id, on= \"advertiserCampaignId\")\n",
    "        dataset = dataset.join(total_p_id, on= \"PublisherId\")\n",
    "        \n",
    "        dataset = dataset.fillna({'pub-id':0,\n",
    "                                 'camp-id':0})\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6360d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1 = fillNaValues()\n",
    "stage2 = reduceCategories()\n",
    "stage3 = StringIndexer(inputCol= \"Country\", outputCol = \"Country_le\")\n",
    "stage4 = StringIndexer(inputCol= \"TrafficType\", outputCol = \"TrafficType_le\")\n",
    "stage5 = StringIndexer(inputCol= \"OS\", outputCol = \"OS_le\")\n",
    "stage6 = StringIndexer(inputCol= \"Browser\", outputCol = \"Browser_le\")\n",
    "\n",
    "stage7 = OneHotEncoder(inputCols = [\"Country_le\",\n",
    "                                      \"Browser_le\",\n",
    "                                      \"OS_le\",\n",
    "                                      \"TrafficType_le\"],\n",
    "                         outputCols = [\"Country_ohe\",\n",
    "                                       \"Browser_ohe\",\n",
    "                                      \"OS_ohe\",\n",
    "                                      \"TrafficType_ohe\"])\n",
    "\n",
    "stage8 = frequencyEncoding()\n",
    "stage9 = VectorAssembler(inputCols = [\"Country_ohe\",\n",
    "                                       \"Browser_ohe\",\n",
    "                                      \"OS_ohe\",\n",
    "                                      \"TrafficType_ohe\",\n",
    "                                     \"Device\",\n",
    "                                     \"Fraud\",\n",
    "                                     \"pub-id\",\n",
    "                                     \"camp-id\"],\n",
    "                        outputCol = \"feature_vector\")\n",
    "\n",
    "stage10 = DecisionTreeClassifier(featuresCol = \"feature_vector\",\n",
    "                                           labelCol = \"ConversionStatus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b1c6d",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bffcba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[stage1,\n",
    "                           stage2,\n",
    "                           stage3,\n",
    "                           stage4,\n",
    "                           stage5,\n",
    "                           stage6,\n",
    "                           stage7,\n",
    "                           stage8,\n",
    "                           stage9,\n",
    "                           stage10])\n",
    "\n",
    "pipeline_model = pipeline.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4306813",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = pipeline_model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33ddbcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol = \"ConversionStatus\", metricName = \"areaUnderROC\")\n",
    "evaluator.evaluate(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aadec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate( pipeline_model.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1562e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate( pipeline_model.transform(valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
